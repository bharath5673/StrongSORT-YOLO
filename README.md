# StrongSORT yolo_multi_model

<br>
<img src="https://media0.giphy.com/media/J19OSJKmqCyP7Mfjt1/giphy.gif" width="80" height="30" />    
<h2>yolo_multi_model </h2>

For an all-in-one Python file that can run detection, segmentation, and pose estimation with various YOLOv5 models (such as YOLOv5, YOLOv7, YOLOv8, and YOLOv11), you should choose a name that clearly reflects the functionality and the models used, while being concise. includes detection, segmentation, and pose estimation) using different YOLO models.

![yolo_multi_model](demo_yoloV8.gif)


![yolo_multi_model](pose_output.gif)


```bash
## recommended conda env python=3.10
## pip install ultralytics -U
$ python yolo_multi_model.py --source 0 1 vid1.mp4 vid2.mp4 --track --count

```




## Acknowledgements

<details><summary> <b>Expand</b> </summary>

* [https://github.com/AlexeyAB/darknet](https://github.com/AlexeyAB/darknet)
* [https://github.com/WongKinYiu/yolor](https://github.com/WongKinYiu/yolor)
* [https://github.com/WongKinYiu/PyTorch_YOLOv4](https://github.com/WongKinYiu/PyTorch_YOLOv4)
* [https://github.com/WongKinYiu/ScaledYOLOv4](https://github.com/WongKinYiu/ScaledYOLOv4)
* [https://github.com/Megvii-BaseDetection/YOLOX](https://github.com/Megvii-BaseDetection/YOLOX)
* [https://github.com/ultralytics/yolov3](https://github.com/ultralytics/yolov3)
* [https://github.com/ultralytics/yolov5](https://github.com/ultralytics/yolov5)
* [https://github.com/DingXiaoH/RepVGG](https://github.com/DingXiaoH/RepVGG)
* [https://github.com/JUGGHM/OREPA_CVPR2022](https://github.com/JUGGHM/OREPA_CVPR2022)
* [https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose](https://github.com/TexasInstruments/edgeai-yolov5/tree/yolo-pose)
* [https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)

</details>

